# -*- coding: utf-8 -*-
"""NLP_Assignment_3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iqQBIAhVXtFRq5-gU_Y2PPF6wuz5NzMz
"""

import re
import spacy
import nltk
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.preprocessing import LabelEncoder
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer

# Load English tokenizer from spaCy
nlp = spacy.load('en_core_web_sm')

# Ensure NLTK stopwords and WordNetLemmatizer are downloaded
nltk.download('stopwords')
nltk.download('wordnet')

data = ['I love programming!', 'Python is amazing...', 'I enjoy solving problems.','i hate c#']
labels = ['positive', 'positive', 'positive', 'negative']

# Initialize the lemmatizer
lemmatizer = WordNetLemmatizer()

# Step 1: Text Cleaning
def clean_text(text):
    # Remove special characters, digits, and punctuation
    text = re.sub(r'[^A-Za-z\s]', '', text)
    # Lowercase the text
    text = text.lower()
    # Remove extra spaces
    text = re.sub(r'\s+', ' ', text).strip()
    return text

data_cleaned = [clean_text(text) for text in data]

# Step 2: Lemmatization using WordNetLemmatizer
def lemmatize_text(text):
    words = text.split()
    lemmatized_words = [lemmatizer.lemmatize(word) for word in words]
    return " ".join(lemmatized_words)

data_lemmatized = [lemmatize_text(text) for text in data_cleaned]

# Step 3: Stop Words Removal
stop_words = set(stopwords.words('english'))
def remove_stop_words(text):
    words = text.split()
    words_filtered = [word for word in words if word not in stop_words]
    return " ".join(words_filtered)

data_no_stopwords = [remove_stop_words(text) for text in data_lemmatized]

# Step 4: Label Encoding
label_encoder = LabelEncoder()


labels_encoded = label_encoder.fit_transform(labels)

# Step 5: TF-IDF Vectorization
tfidf_vectorizer = TfidfVectorizer()
tfidf_matrix = tfidf_vectorizer.fit_transform(data_no_stopwords)

# Output the results
print("Cleaned and Lemmatized Text (no stopwords):")
print(data_no_stopwords)
print()
print("Encoded Labels:")
print(labels_encoded)
print()
print("TF-IDF Matrix:")
print(tfidf_matrix.toarray())

